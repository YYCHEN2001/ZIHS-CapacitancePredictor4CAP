{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 模型评估",
   "id": "a1cb97dfd83b7199"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 读取数据",
   "id": "85fcb44c26cfa28e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T05:21:18.936382Z",
     "start_time": "2024-04-19T05:21:16.919353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.models import load_data_dopants, dataset_split_10class, metrics_to_dataframe\n",
    "\n",
    "# 读取数据\n",
    "filepath = '../data/processed/data_dopants.csv'\n",
    "data = load_data_dopants(filepath)\n",
    "\n",
    "# 按10个等级分割数据集，同时标准化数据\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = dataset_split_10class(data)"
   ],
   "id": "c50adf0cdd33ceae",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. 核岭回归（Kernel Ridge Regression）",
   "id": "4b6582db519e58a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T05:21:19.070614Z",
     "start_time": "2024-04-19T05:21:18.937904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "# 初始化模型\n",
    "krr = KernelRidge(alpha=1.04,\n",
    "                  gamma=1.02,\n",
    "                  kernel='polynomial',\n",
    "                  degree=1,\n",
    "                  coef0=1.52)\n",
    "\n",
    "# 训练模型\n",
    "krr.fit(X_train_scaled, y_train)\n",
    "y_train_pred = krr.predict(X_train_scaled)\n",
    "y_test_pred = krr.predict(X_test_scaled)\n",
    "\n",
    "krr_df = metrics_to_dataframe(y_train, y_train_pred, y_test, y_test_pred, 'KRR')\n",
    "krr_df"
   ],
   "id": "44d7028a9af933a1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  model  R2_train  MAE_train  MAPE_train  RMSE_train  R2_test   MAE_test  \\\n",
       "0   KRR  0.435135  22.894784   31.818375   30.408537  0.44676  23.182953   \n",
       "\n",
       "   MAPE_test  RMSE_test  \n",
       "0  31.754049  30.803639  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>R2_train</th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>MAPE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>R2_test</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>MAPE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KRR</td>\n",
       "      <td>0.435135</td>\n",
       "      <td>22.894784</td>\n",
       "      <td>31.818375</td>\n",
       "      <td>30.408537</td>\n",
       "      <td>0.44676</td>\n",
       "      <td>23.182953</td>\n",
       "      <td>31.754049</td>\n",
       "      <td>30.803639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. 支持向量回归（Support Vector Regression）",
   "id": "ee52a5bd16bcdd26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T05:21:19.122901Z",
     "start_time": "2024-04-19T05:21:19.072130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# 初始化模型，这里使用支持向量回归\n",
    "svr = SVR(C=2.57, \n",
    "          kernel='poly', \n",
    "          degree=3, \n",
    "          gamma='scale', \n",
    "          coef0=4.9, \n",
    "          epsilon=0.75)\n",
    "\n",
    "# 训练模型\n",
    "svr.fit(X_train_scaled, y_train)\n",
    "y_train_pred = svr.predict(X_train_scaled)\n",
    "y_test_pred = svr.predict(X_test_scaled)\n",
    "\n",
    "svr_df = metrics_to_dataframe(y_train, y_train_pred, y_test, y_test_pred, 'SVR')\n",
    "svr_df"
   ],
   "id": "db21222c9837c226",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  model  R2_train  MAE_train  MAPE_train  RMSE_train   R2_test   MAE_test  \\\n",
       "0   SVR  0.711955  14.185514   16.157653   21.714667  0.673651  17.315961   \n",
       "\n",
       "   MAPE_test  RMSE_test  \n",
       "0   21.28754  23.658464  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>R2_train</th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>MAPE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>R2_test</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>MAPE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.711955</td>\n",
       "      <td>14.185514</td>\n",
       "      <td>16.157653</td>\n",
       "      <td>21.714667</td>\n",
       "      <td>0.673651</td>\n",
       "      <td>17.315961</td>\n",
       "      <td>21.28754</td>\n",
       "      <td>23.658464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. 随机森林回归（Random Forest Regression）",
   "id": "9e1c7469f2323714"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T05:21:20.161287Z",
     "start_time": "2024-04-19T05:21:19.124417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=140,\n",
    "                            max_depth=12,\n",
    "                            min_samples_leaf=1,\n",
    "                            min_samples_split=2,\n",
    "                            random_state=21)\n",
    "\n",
    "# 训练模型\n",
    "rfr.fit(X_train_scaled, y_train)\n",
    "y_train_pred = rfr.predict(X_train_scaled)\n",
    "y_test_pred = rfr.predict(X_test_scaled)\n",
    "\n",
    "rfr_df = metrics_to_dataframe(y_train, y_train_pred, y_test, y_test_pred, 'RF')\n",
    "rfr_df"
   ],
   "id": "a05322779e918067",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  model  R2_train  MAE_train  MAPE_train  RMSE_train   R2_test   MAE_test  \\\n",
       "0    RF   0.97968   3.836267    4.787475     5.76751  0.844773  10.142849   \n",
       "\n",
       "   MAPE_test  RMSE_test  \n",
       "0  13.554456  16.316589  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>R2_train</th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>MAPE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>R2_test</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>MAPE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.97968</td>\n",
       "      <td>3.836267</td>\n",
       "      <td>4.787475</td>\n",
       "      <td>5.76751</td>\n",
       "      <td>0.844773</td>\n",
       "      <td>10.142849</td>\n",
       "      <td>13.554456</td>\n",
       "      <td>16.316589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. 梯度提升回归（Gradient Boosting Regression）",
   "id": "1435d2976761a382"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T05:21:20.491878Z",
     "start_time": "2024-04-19T05:21:20.165185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# 初始化模型\n",
    "gbr = GradientBoostingRegressor(n_estimators=200,\n",
    "                                alpha=0.07,\n",
    "                                learning_rate=0.14,\n",
    "                                max_depth=9,\n",
    "                                max_features=0.2,\n",
    "                                min_samples_leaf=3,\n",
    "                                min_samples_split=7,\n",
    "                                subsample=0.8,\n",
    "                                random_state=21)\n",
    "\n",
    "# 训练模型\n",
    "gbr.fit(X_train_scaled, y_train)\n",
    "y_train_pred = gbr.predict(X_train_scaled)\n",
    "y_test_pred = gbr.predict(X_test_scaled)\n",
    "\n",
    "gbr_df = metrics_to_dataframe(y_train, y_train_pred, y_test, y_test_pred, 'GBR')\n",
    "gbr_df"
   ],
   "id": "4a3da29a88608c92",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  model  R2_train  MAE_train  MAPE_train  RMSE_train   R2_test  MAE_test  \\\n",
       "0   GBR  0.998413   1.072222    1.302167    1.611991  0.918238    6.5527   \n",
       "\n",
       "   MAPE_test  RMSE_test  \n",
       "0   8.510915  11.841927  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>R2_train</th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>MAPE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>R2_test</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>MAPE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GBR</td>\n",
       "      <td>0.998413</td>\n",
       "      <td>1.072222</td>\n",
       "      <td>1.302167</td>\n",
       "      <td>1.611991</td>\n",
       "      <td>0.918238</td>\n",
       "      <td>6.5527</td>\n",
       "      <td>8.510915</td>\n",
       "      <td>11.841927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. XGBoost回归（XGBoost Regression）",
   "id": "7c6b919fd31a2ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T05:21:21.521713Z",
     "start_time": "2024-04-19T05:21:20.494530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# 初始化模型，这里使用XGBoost回归器\n",
    "xgb = XGBRegressor(n_estimators=190,\n",
    "                             learning_rate=0.15,\n",
    "                             subsample=0.5,\n",
    "                             gamma=0.1,\n",
    "                             max_depth=8,\n",
    "                             min_child_weight=2,\n",
    "                             reg_alpha=0.34,\n",
    "                             colsample_bytree=1.0,\n",
    "                             colsample_bylevel=0.3,\n",
    "                             colsample_bynode=0.7,\n",
    "                             random_state=21)\n",
    "\n",
    "# 训练模型\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "y_train_pred = xgb.predict(X_train_scaled)\n",
    "y_test_pred = xgb.predict(X_test_scaled)\n",
    "\n",
    "xgb_df = metrics_to_dataframe(y_train, y_train_pred, y_test, y_test_pred, 'XGB')\n",
    "xgb_df"
   ],
   "id": "c3666e8630187f85",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  model  R2_train  MAE_train  MAPE_train  RMSE_train   R2_test  MAE_test  \\\n",
       "0   XGB  0.995994   1.843803    2.196843    2.560729  0.928432   6.58921   \n",
       "\n",
       "   MAPE_test  RMSE_test  \n",
       "0   8.734536   11.07911  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>R2_train</th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>MAPE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>R2_test</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>MAPE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.995994</td>\n",
       "      <td>1.843803</td>\n",
       "      <td>2.196843</td>\n",
       "      <td>2.560729</td>\n",
       "      <td>0.928432</td>\n",
       "      <td>6.58921</td>\n",
       "      <td>8.734536</td>\n",
       "      <td>11.07911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. ANN回归（Artificial Neural Network Regression）",
   "id": "20ce510cf1d3cd37"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T05:22:17.719844Z",
     "start_time": "2024-04-19T05:21:21.524759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# 初始化ANN模型\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1)  # 输出层：一个神经元，无激活函数，用于回归任务\n",
    "])\n",
    "\n",
    "# 编译模型，指定优化器、损失函数和评价指标\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# 初始化早停回调\n",
    "early_stopper = EarlyStopping(\n",
    "    monitor='val_loss',     # 监控验证集损失\n",
    "    min_delta=0.01,        # 表示监控指标至少需要改善 0.001\n",
    "    patience=50,            # 如果30个epoch内验证集损失没有改善，则提前停止训练\n",
    "    verbose=1,              # 输出早停信息\n",
    "    mode='min',             # 监控的指标是损失，应该减小\n",
    "    restore_best_weights=True  # 训练结束后，模型权重回滚到最佳状态\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.3,  # 使用20%的数据作为验证集\n",
    "    epochs=500,  # 最大训练轮数\n",
    "    callbacks=[early_stopper],  # 使用早停机制\n",
    "    verbose=1  # 输出训练信息\n",
    ")\n",
    "\n",
    "# 预测训练集和测试集\n",
    "y_train_pred = model.predict(X_train_scaled).flatten()\n",
    "y_test_pred = model.predict(X_test_scaled).flatten()\n",
    "\n",
    "# 计算评价指标\n",
    "ann_df = metrics_to_dataframe(y_train, y_train_pred, y_test, y_test_pred, 'ANN')\n",
    "ann_df"
   ],
   "id": "b92d9a03962b1592",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\41315\\anaconda3\\envs\\sklearn-env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 42ms/step - loss: 10248.2373 - mae: 91.7689 - val_loss: 11085.2471 - val_mae: 97.3046\n",
      "Epoch 2/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 9425.1455 - mae: 88.7413 - val_loss: 10309.5371 - val_mae: 93.2766\n",
      "Epoch 3/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8525.9668 - mae: 83.5612 - val_loss: 8884.0928 - val_mae: 85.3778\n",
      "Epoch 4/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 7109.7822 - mae: 74.0756 - val_loss: 6429.0693 - val_mae: 69.8430\n",
      "Epoch 5/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 4838.9277 - mae: 57.1854 - val_loss: 3259.8501 - val_mae: 45.1122\n",
      "Epoch 6/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - loss: 2251.5933 - mae: 37.5047 - val_loss: 1792.4277 - val_mae: 32.3068\n",
      "Epoch 7/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 1573.6234 - mae: 30.4786 - val_loss: 1541.5317 - val_mae: 30.2424\n",
      "Epoch 8/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1601.7440 - mae: 30.1723 - val_loss: 1556.7067 - val_mae: 29.2279\n",
      "Epoch 9/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1213.8558 - mae: 26.0152 - val_loss: 1425.2810 - val_mae: 28.2094\n",
      "Epoch 10/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1051.5521 - mae: 24.4863 - val_loss: 1239.3430 - val_mae: 26.8975\n",
      "Epoch 11/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 973.7482 - mae: 23.6743 - val_loss: 1173.0255 - val_mae: 26.1632\n",
      "Epoch 12/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1007.3012 - mae: 23.5001 - val_loss: 1122.5634 - val_mae: 25.4704\n",
      "Epoch 13/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 937.0263 - mae: 22.8943 - val_loss: 1072.9635 - val_mae: 24.8055\n",
      "Epoch 14/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 851.8707 - mae: 22.1199 - val_loss: 1014.1977 - val_mae: 24.2698\n",
      "Epoch 15/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 863.2521 - mae: 21.7619 - val_loss: 967.9622 - val_mae: 23.7239\n",
      "Epoch 16/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 942.1365 - mae: 21.8822 - val_loss: 926.2496 - val_mae: 23.3550\n",
      "Epoch 17/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 721.5223 - mae: 19.6916 - val_loss: 911.4012 - val_mae: 22.9247\n",
      "Epoch 18/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 900.9650 - mae: 21.4319 - val_loss: 844.0121 - val_mae: 22.6918\n",
      "Epoch 19/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 768.3940 - mae: 21.0805 - val_loss: 839.4059 - val_mae: 22.3947\n",
      "Epoch 20/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 692.1760 - mae: 19.8300 - val_loss: 812.3964 - val_mae: 22.0322\n",
      "Epoch 21/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 778.6816 - mae: 20.9170 - val_loss: 770.2571 - val_mae: 21.8412\n",
      "Epoch 22/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 716.2161 - mae: 19.7692 - val_loss: 790.4085 - val_mae: 21.4885\n",
      "Epoch 23/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 782.6940 - mae: 20.6516 - val_loss: 743.8713 - val_mae: 21.1476\n",
      "Epoch 24/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 779.2553 - mae: 20.4060 - val_loss: 718.7126 - val_mae: 20.9443\n",
      "Epoch 25/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 630.2761 - mae: 18.4822 - val_loss: 722.3218 - val_mae: 20.6851\n",
      "Epoch 26/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 626.3493 - mae: 18.5337 - val_loss: 702.8129 - val_mae: 20.6058\n",
      "Epoch 27/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 759.8619 - mae: 19.6643 - val_loss: 670.5650 - val_mae: 20.1833\n",
      "Epoch 28/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 777.0095 - mae: 19.7635 - val_loss: 692.4124 - val_mae: 20.2861\n",
      "Epoch 29/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 542.0355 - mae: 17.3587 - val_loss: 660.8179 - val_mae: 19.9411\n",
      "Epoch 30/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 626.2745 - mae: 18.6896 - val_loss: 642.6562 - val_mae: 19.8092\n",
      "Epoch 31/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 618.1359 - mae: 18.2726 - val_loss: 644.2683 - val_mae: 19.7251\n",
      "Epoch 32/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 513.3129 - mae: 16.8393 - val_loss: 640.3867 - val_mae: 19.5610\n",
      "Epoch 33/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 574.9389 - mae: 17.9511 - val_loss: 607.8301 - val_mae: 19.2075\n",
      "Epoch 34/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 665.3567 - mae: 18.2247 - val_loss: 620.9012 - val_mae: 19.2694\n",
      "Epoch 35/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 517.7129 - mae: 17.0006 - val_loss: 596.9850 - val_mae: 18.9955\n",
      "Epoch 36/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 514.4976 - mae: 17.1522 - val_loss: 588.5602 - val_mae: 18.8378\n",
      "Epoch 37/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 592.5113 - mae: 17.6382 - val_loss: 575.7703 - val_mae: 18.6545\n",
      "Epoch 38/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 605.1501 - mae: 17.8542 - val_loss: 593.3063 - val_mae: 18.7503\n",
      "Epoch 39/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 485.1434 - mae: 16.1790 - val_loss: 559.8842 - val_mae: 18.4199\n",
      "Epoch 40/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 578.8896 - mae: 17.7913 - val_loss: 559.5817 - val_mae: 18.3588\n",
      "Epoch 41/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 534.9881 - mae: 16.7116 - val_loss: 576.2961 - val_mae: 18.3737\n",
      "Epoch 42/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 416.4632 - mae: 15.3382 - val_loss: 540.3443 - val_mae: 17.8970\n",
      "Epoch 43/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 581.1494 - mae: 17.5019 - val_loss: 533.8616 - val_mae: 17.9163\n",
      "Epoch 44/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 469.2202 - mae: 16.4878 - val_loss: 541.2817 - val_mae: 17.9377\n",
      "Epoch 45/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 495.0975 - mae: 16.1258 - val_loss: 514.3847 - val_mae: 17.7002\n",
      "Epoch 46/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 523.0347 - mae: 16.9733 - val_loss: 536.4963 - val_mae: 17.7087\n",
      "Epoch 47/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 414.1654 - mae: 15.4678 - val_loss: 511.9019 - val_mae: 17.4552\n",
      "Epoch 48/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 563.7577 - mae: 16.6208 - val_loss: 511.0108 - val_mae: 17.4334\n",
      "Epoch 49/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 544.3923 - mae: 16.6071 - val_loss: 505.2805 - val_mae: 17.3041\n",
      "Epoch 50/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 517.4241 - mae: 16.1338 - val_loss: 503.4285 - val_mae: 17.2818\n",
      "Epoch 51/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 518.4454 - mae: 16.0480 - val_loss: 496.4295 - val_mae: 17.1504\n",
      "Epoch 52/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 449.0446 - mae: 15.3774 - val_loss: 490.3191 - val_mae: 16.9941\n",
      "Epoch 53/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 462.6603 - mae: 15.6810 - val_loss: 484.0687 - val_mae: 17.0069\n",
      "Epoch 54/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 510.1512 - mae: 16.0624 - val_loss: 485.8418 - val_mae: 16.9454\n",
      "Epoch 55/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 429.1252 - mae: 15.2874 - val_loss: 473.9494 - val_mae: 16.7936\n",
      "Epoch 56/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 589.6697 - mae: 17.3009 - val_loss: 466.3818 - val_mae: 16.5724\n",
      "Epoch 57/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 429.7634 - mae: 14.1710 - val_loss: 472.1825 - val_mae: 16.5977\n",
      "Epoch 58/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 431.1738 - mae: 14.7438 - val_loss: 460.4890 - val_mae: 16.4672\n",
      "Epoch 59/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 357.2039 - mae: 13.8019 - val_loss: 453.5141 - val_mae: 16.3626\n",
      "Epoch 60/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 409.1928 - mae: 14.7682 - val_loss: 444.8474 - val_mae: 16.1278\n",
      "Epoch 61/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 440.5121 - mae: 14.8021 - val_loss: 446.6164 - val_mae: 16.1908\n",
      "Epoch 62/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 354.8770 - mae: 13.4449 - val_loss: 437.4708 - val_mae: 16.1349\n",
      "Epoch 63/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 356.3220 - mae: 14.0463 - val_loss: 426.5125 - val_mae: 15.8562\n",
      "Epoch 64/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 438.5932 - mae: 15.0687 - val_loss: 431.7810 - val_mae: 15.9967\n",
      "Epoch 65/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 362.5546 - mae: 13.4289 - val_loss: 430.4075 - val_mae: 15.9047\n",
      "Epoch 66/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 379.9922 - mae: 13.8858 - val_loss: 424.8202 - val_mae: 15.9646\n",
      "Epoch 67/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 364.5603 - mae: 13.9257 - val_loss: 429.4433 - val_mae: 15.9350\n",
      "Epoch 68/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 336.5047 - mae: 13.6505 - val_loss: 413.2681 - val_mae: 15.7310\n",
      "Epoch 69/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 305.2251 - mae: 13.2781 - val_loss: 406.7208 - val_mae: 15.5142\n",
      "Epoch 70/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 292.2808 - mae: 12.7635 - val_loss: 399.8116 - val_mae: 15.5309\n",
      "Epoch 71/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 321.5384 - mae: 12.9125 - val_loss: 417.0610 - val_mae: 15.8177\n",
      "Epoch 72/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 313.1654 - mae: 13.2374 - val_loss: 409.6621 - val_mae: 15.6786\n",
      "Epoch 73/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 367.0569 - mae: 14.0094 - val_loss: 390.4078 - val_mae: 15.3935\n",
      "Epoch 74/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 395.7997 - mae: 14.2498 - val_loss: 397.3235 - val_mae: 15.4094\n",
      "Epoch 75/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 283.9134 - mae: 11.9132 - val_loss: 395.7427 - val_mae: 15.4311\n",
      "Epoch 76/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 343.2150 - mae: 12.5534 - val_loss: 385.2486 - val_mae: 15.2043\n",
      "Epoch 77/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 293.6014 - mae: 12.0591 - val_loss: 387.5854 - val_mae: 15.3208\n",
      "Epoch 78/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 286.8406 - mae: 12.1281 - val_loss: 389.4736 - val_mae: 15.1714\n",
      "Epoch 79/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 286.4507 - mae: 12.2114 - val_loss: 384.4900 - val_mae: 15.2772\n",
      "Epoch 80/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 298.3052 - mae: 12.3283 - val_loss: 374.6939 - val_mae: 14.8920\n",
      "Epoch 81/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 270.6744 - mae: 11.6918 - val_loss: 376.7072 - val_mae: 15.0887\n",
      "Epoch 82/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 346.4099 - mae: 12.7432 - val_loss: 370.7246 - val_mae: 15.1310\n",
      "Epoch 83/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 293.8531 - mae: 12.1455 - val_loss: 381.5013 - val_mae: 15.0573\n",
      "Epoch 84/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 302.4474 - mae: 11.7511 - val_loss: 359.2781 - val_mae: 14.8926\n",
      "Epoch 85/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 321.1291 - mae: 12.5325 - val_loss: 379.2005 - val_mae: 14.8841\n",
      "Epoch 86/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 261.8338 - mae: 11.2420 - val_loss: 363.3062 - val_mae: 15.0593\n",
      "Epoch 87/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 266.3415 - mae: 11.6671 - val_loss: 363.1989 - val_mae: 14.7274\n",
      "Epoch 88/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 274.3270 - mae: 11.3431 - val_loss: 341.1197 - val_mae: 14.4110\n",
      "Epoch 89/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 271.7474 - mae: 11.8060 - val_loss: 369.4403 - val_mae: 14.8530\n",
      "Epoch 90/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 371.7561 - mae: 13.0748 - val_loss: 365.6556 - val_mae: 14.6741\n",
      "Epoch 91/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 242.1573 - mae: 10.7454 - val_loss: 345.5454 - val_mae: 14.6307\n",
      "Epoch 92/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 288.6719 - mae: 11.9750 - val_loss: 342.6985 - val_mae: 14.2708\n",
      "Epoch 93/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 304.4593 - mae: 11.9592 - val_loss: 347.2430 - val_mae: 14.3403\n",
      "Epoch 94/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 229.8797 - mae: 10.4281 - val_loss: 353.4503 - val_mae: 14.5435\n",
      "Epoch 95/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 208.6375 - mae: 10.4379 - val_loss: 340.3278 - val_mae: 14.2435\n",
      "Epoch 96/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 251.1899 - mae: 11.3744 - val_loss: 327.9818 - val_mae: 14.2044\n",
      "Epoch 97/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 206.6948 - mae: 10.3269 - val_loss: 338.2185 - val_mae: 14.1539\n",
      "Epoch 98/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 245.3604 - mae: 11.1833 - val_loss: 340.3257 - val_mae: 14.2109\n",
      "Epoch 99/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 242.0391 - mae: 10.5185 - val_loss: 326.2988 - val_mae: 14.1315\n",
      "Epoch 100/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 274.8039 - mae: 11.1959 - val_loss: 340.3740 - val_mae: 14.0743\n",
      "Epoch 101/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 265.9129 - mae: 10.7937 - val_loss: 332.2285 - val_mae: 13.9043\n",
      "Epoch 102/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 237.7577 - mae: 10.2909 - val_loss: 330.3039 - val_mae: 14.3382\n",
      "Epoch 103/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 254.4981 - mae: 11.6462 - val_loss: 333.5502 - val_mae: 13.9633\n",
      "Epoch 104/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 246.5101 - mae: 10.8034 - val_loss: 320.0355 - val_mae: 14.0056\n",
      "Epoch 105/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 215.3999 - mae: 10.2249 - val_loss: 322.6841 - val_mae: 13.6752\n",
      "Epoch 106/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 215.0136 - mae: 10.3293 - val_loss: 314.8242 - val_mae: 13.7068\n",
      "Epoch 107/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 255.1168 - mae: 10.9674 - val_loss: 317.6769 - val_mae: 13.7503\n",
      "Epoch 108/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 207.0061 - mae: 10.0908 - val_loss: 330.8510 - val_mae: 13.8943\n",
      "Epoch 109/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 212.1720 - mae: 9.7963 - val_loss: 315.0447 - val_mae: 13.7475\n",
      "Epoch 110/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 174.5946 - mae: 9.3203 - val_loss: 316.8001 - val_mae: 14.0208\n",
      "Epoch 111/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 206.0970 - mae: 10.0018 - val_loss: 314.7909 - val_mae: 13.4731\n",
      "Epoch 112/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 201.1114 - mae: 9.2358 - val_loss: 326.5044 - val_mae: 14.0418\n",
      "Epoch 113/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 178.8911 - mae: 8.9848 - val_loss: 314.2909 - val_mae: 13.9206\n",
      "Epoch 114/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 207.7733 - mae: 10.2173 - val_loss: 307.1354 - val_mae: 13.3756\n",
      "Epoch 115/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 216.7241 - mae: 9.8149 - val_loss: 302.9849 - val_mae: 13.3268\n",
      "Epoch 116/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 231.4383 - mae: 10.0267 - val_loss: 320.4404 - val_mae: 13.6461\n",
      "Epoch 117/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 189.6984 - mae: 9.5317 - val_loss: 310.1340 - val_mae: 13.8358\n",
      "Epoch 118/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 182.5979 - mae: 9.3321 - val_loss: 296.5835 - val_mae: 13.1628\n",
      "Epoch 119/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 189.3013 - mae: 9.4724 - val_loss: 303.3193 - val_mae: 13.3235\n",
      "Epoch 120/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 163.2002 - mae: 8.8958 - val_loss: 322.8361 - val_mae: 14.1092\n",
      "Epoch 121/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 217.2457 - mae: 10.5698 - val_loss: 303.6671 - val_mae: 13.3775\n",
      "Epoch 122/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 175.8586 - mae: 8.7040 - val_loss: 282.7969 - val_mae: 13.1281\n",
      "Epoch 123/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 207.8008 - mae: 10.4753 - val_loss: 320.6541 - val_mae: 13.1564\n",
      "Epoch 124/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 188.3584 - mae: 9.1924 - val_loss: 296.2592 - val_mae: 13.3138\n",
      "Epoch 125/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 199.4601 - mae: 9.6805 - val_loss: 292.3385 - val_mae: 12.9421\n",
      "Epoch 126/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 189.1432 - mae: 8.9486 - val_loss: 296.0597 - val_mae: 12.9226\n",
      "Epoch 127/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 183.0060 - mae: 9.0366 - val_loss: 295.6383 - val_mae: 13.1522\n",
      "Epoch 128/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 148.2972 - mae: 8.1401 - val_loss: 313.5065 - val_mae: 13.7172\n",
      "Epoch 129/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 213.0905 - mae: 10.0725 - val_loss: 320.8256 - val_mae: 13.0864\n",
      "Epoch 130/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 200.1525 - mae: 9.4459 - val_loss: 294.2452 - val_mae: 13.2481\n",
      "Epoch 131/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 167.5457 - mae: 8.8498 - val_loss: 292.9229 - val_mae: 13.0286\n",
      "Epoch 132/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 184.0822 - mae: 9.0818 - val_loss: 297.3715 - val_mae: 13.0440\n",
      "Epoch 133/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 150.6568 - mae: 8.4405 - val_loss: 289.5280 - val_mae: 12.5914\n",
      "Epoch 134/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 186.6461 - mae: 8.8869 - val_loss: 297.3509 - val_mae: 13.0624\n",
      "Epoch 135/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 168.8969 - mae: 8.9687 - val_loss: 280.1741 - val_mae: 12.5239\n",
      "Epoch 136/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 190.5822 - mae: 9.0433 - val_loss: 273.8946 - val_mae: 12.6274\n",
      "Epoch 137/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 176.5749 - mae: 9.2556 - val_loss: 298.7047 - val_mae: 12.8956\n",
      "Epoch 138/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 165.2184 - mae: 8.6935 - val_loss: 297.2909 - val_mae: 13.0254\n",
      "Epoch 139/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 178.7754 - mae: 9.3216 - val_loss: 269.1464 - val_mae: 12.1950\n",
      "Epoch 140/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 169.5519 - mae: 8.6696 - val_loss: 280.4025 - val_mae: 12.3581\n",
      "Epoch 141/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 150.9919 - mae: 8.0175 - val_loss: 293.5122 - val_mae: 12.7249\n",
      "Epoch 142/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 211.3640 - mae: 9.7060 - val_loss: 281.6002 - val_mae: 12.4036\n",
      "Epoch 143/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 188.0957 - mae: 8.8801 - val_loss: 269.9547 - val_mae: 12.6247\n",
      "Epoch 144/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 167.1067 - mae: 8.8485 - val_loss: 290.2517 - val_mae: 12.6244\n",
      "Epoch 145/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 186.2854 - mae: 8.7291 - val_loss: 273.3194 - val_mae: 12.3281\n",
      "Epoch 146/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 151.1325 - mae: 8.1911 - val_loss: 269.2834 - val_mae: 12.4617\n",
      "Epoch 147/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 206.8426 - mae: 9.4171 - val_loss: 280.0187 - val_mae: 12.4195\n",
      "Epoch 148/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 180.4632 - mae: 8.7896 - val_loss: 275.2156 - val_mae: 12.5399\n",
      "Epoch 149/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 157.6058 - mae: 8.5232 - val_loss: 267.7418 - val_mae: 12.0660\n",
      "Epoch 150/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 184.0405 - mae: 8.5330 - val_loss: 272.0017 - val_mae: 12.3394\n",
      "Epoch 151/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 168.7484 - mae: 8.4143 - val_loss: 277.7619 - val_mae: 12.4961\n",
      "Epoch 152/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 137.3234 - mae: 7.7550 - val_loss: 273.3028 - val_mae: 12.4055\n",
      "Epoch 153/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 176.5141 - mae: 8.5594 - val_loss: 260.2037 - val_mae: 11.9648\n",
      "Epoch 154/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 142.6428 - mae: 7.8859 - val_loss: 271.7812 - val_mae: 12.3643\n",
      "Epoch 155/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 115.7652 - mae: 7.0563 - val_loss: 277.3109 - val_mae: 12.3188\n",
      "Epoch 156/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 124.2641 - mae: 7.8520 - val_loss: 253.9034 - val_mae: 12.1442\n",
      "Epoch 157/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 152.8737 - mae: 8.5191 - val_loss: 293.2657 - val_mae: 12.7193\n",
      "Epoch 158/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 149.0499 - mae: 7.9076 - val_loss: 283.6122 - val_mae: 12.8617\n",
      "Epoch 159/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 129.0483 - mae: 7.8943 - val_loss: 278.4995 - val_mae: 12.6323\n",
      "Epoch 160/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 162.5962 - mae: 8.9632 - val_loss: 265.6346 - val_mae: 12.0410\n",
      "Epoch 161/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 147.9321 - mae: 7.8886 - val_loss: 264.1733 - val_mae: 12.2180\n",
      "Epoch 162/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 147.9884 - mae: 8.0043 - val_loss: 268.1047 - val_mae: 12.4601\n",
      "Epoch 163/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 136.3763 - mae: 8.1231 - val_loss: 268.1337 - val_mae: 12.1133\n",
      "Epoch 164/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 133.9224 - mae: 7.5866 - val_loss: 259.6175 - val_mae: 11.9545\n",
      "Epoch 165/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 139.2238 - mae: 7.6242 - val_loss: 262.6128 - val_mae: 12.1326\n",
      "Epoch 166/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 145.6734 - mae: 8.2929 - val_loss: 267.2477 - val_mae: 12.1400\n",
      "Epoch 167/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 168.7500 - mae: 9.4041 - val_loss: 306.1915 - val_mae: 12.7124\n",
      "Epoch 168/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 143.5693 - mae: 8.6442 - val_loss: 306.4381 - val_mae: 13.7155\n",
      "Epoch 169/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 185.3521 - mae: 10.0012 - val_loss: 266.6109 - val_mae: 11.9084\n",
      "Epoch 170/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 134.3278 - mae: 7.5749 - val_loss: 260.2317 - val_mae: 11.8597\n",
      "Epoch 171/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 156.1601 - mae: 8.3244 - val_loss: 267.1942 - val_mae: 12.0154\n",
      "Epoch 172/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 131.1311 - mae: 7.4014 - val_loss: 259.8651 - val_mae: 12.0621\n",
      "Epoch 173/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 137.2855 - mae: 7.4919 - val_loss: 257.0053 - val_mae: 11.7175\n",
      "Epoch 174/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 152.6360 - mae: 8.0981 - val_loss: 255.5780 - val_mae: 11.7853\n",
      "Epoch 175/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 141.3695 - mae: 7.8756 - val_loss: 253.5034 - val_mae: 11.7316\n",
      "Epoch 176/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 108.2295 - mae: 6.5094 - val_loss: 274.0410 - val_mae: 12.4211\n",
      "Epoch 177/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 142.5790 - mae: 7.8915 - val_loss: 243.2777 - val_mae: 11.4157\n",
      "Epoch 178/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 124.3006 - mae: 6.9607 - val_loss: 254.8480 - val_mae: 11.7236\n",
      "Epoch 179/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 116.2587 - mae: 6.9249 - val_loss: 272.3725 - val_mae: 12.3092\n",
      "Epoch 180/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 125.6133 - mae: 7.3578 - val_loss: 251.8734 - val_mae: 11.4306\n",
      "Epoch 181/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 115.9125 - mae: 7.3239 - val_loss: 270.9107 - val_mae: 12.1581\n",
      "Epoch 182/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 145.0717 - mae: 8.0388 - val_loss: 244.0312 - val_mae: 11.5309\n",
      "Epoch 183/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 115.6320 - mae: 7.0925 - val_loss: 261.5425 - val_mae: 11.8281\n",
      "Epoch 184/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 149.7491 - mae: 8.1776 - val_loss: 241.2751 - val_mae: 11.3415\n",
      "Epoch 185/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 104.4201 - mae: 6.7256 - val_loss: 252.2626 - val_mae: 11.5355\n",
      "Epoch 186/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 122.4850 - mae: 7.1881 - val_loss: 241.9270 - val_mae: 11.4110\n",
      "Epoch 187/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 129.8982 - mae: 7.2674 - val_loss: 255.2323 - val_mae: 11.7116\n",
      "Epoch 188/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 131.1880 - mae: 7.1841 - val_loss: 254.5839 - val_mae: 11.7990\n",
      "Epoch 189/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 132.8410 - mae: 8.1020 - val_loss: 233.9637 - val_mae: 11.1361\n",
      "Epoch 190/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 155.3423 - mae: 8.1532 - val_loss: 264.7506 - val_mae: 11.7874\n",
      "Epoch 191/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 171.2555 - mae: 8.3648 - val_loss: 243.5604 - val_mae: 11.2210\n",
      "Epoch 192/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 176.9713 - mae: 8.2883 - val_loss: 248.8827 - val_mae: 11.5020\n",
      "Epoch 193/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 133.0929 - mae: 7.6449 - val_loss: 233.3933 - val_mae: 11.2213\n",
      "Epoch 194/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 120.4728 - mae: 7.2659 - val_loss: 244.5091 - val_mae: 11.2459\n",
      "Epoch 195/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 121.4536 - mae: 7.0689 - val_loss: 243.2495 - val_mae: 11.3883\n",
      "Epoch 196/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 147.4970 - mae: 7.7146 - val_loss: 243.0044 - val_mae: 11.1237\n",
      "Epoch 197/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 126.4109 - mae: 7.1534 - val_loss: 242.8324 - val_mae: 11.2902\n",
      "Epoch 198/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 120.7171 - mae: 7.2517 - val_loss: 247.2265 - val_mae: 11.6554\n",
      "Epoch 199/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 145.5881 - mae: 7.7955 - val_loss: 253.2260 - val_mae: 11.5742\n",
      "Epoch 200/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 120.5256 - mae: 7.5436 - val_loss: 243.3911 - val_mae: 11.1586\n",
      "Epoch 201/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 119.5500 - mae: 7.5052 - val_loss: 238.0850 - val_mae: 11.0190\n",
      "Epoch 202/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 152.4339 - mae: 7.9236 - val_loss: 260.7704 - val_mae: 12.1194\n",
      "Epoch 203/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 121.0667 - mae: 7.3197 - val_loss: 248.8742 - val_mae: 11.5703\n",
      "Epoch 204/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 131.4313 - mae: 7.8551 - val_loss: 258.7129 - val_mae: 11.2867\n",
      "Epoch 205/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 154.2481 - mae: 8.2349 - val_loss: 259.8576 - val_mae: 11.6830\n",
      "Epoch 206/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 138.0987 - mae: 7.4494 - val_loss: 241.1264 - val_mae: 11.0626\n",
      "Epoch 207/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 119.0273 - mae: 7.2921 - val_loss: 238.7791 - val_mae: 11.0494\n",
      "Epoch 208/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 112.0664 - mae: 6.9447 - val_loss: 252.8078 - val_mae: 11.7950\n",
      "Epoch 209/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 113.5832 - mae: 7.2521 - val_loss: 274.4890 - val_mae: 12.3867\n",
      "Epoch 210/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 118.4212 - mae: 7.4260 - val_loss: 232.1345 - val_mae: 10.9632\n",
      "Epoch 211/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 125.5271 - mae: 7.3102 - val_loss: 225.4488 - val_mae: 10.7567\n",
      "Epoch 212/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 127.1510 - mae: 7.1571 - val_loss: 248.1222 - val_mae: 11.4482\n",
      "Epoch 213/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 114.1853 - mae: 6.6372 - val_loss: 238.1975 - val_mae: 11.1887\n",
      "Epoch 214/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 146.0006 - mae: 7.8661 - val_loss: 233.5514 - val_mae: 10.7111\n",
      "Epoch 215/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 95.9119 - mae: 6.5373 - val_loss: 241.1827 - val_mae: 11.2319\n",
      "Epoch 216/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 144.9171 - mae: 7.5613 - val_loss: 225.8833 - val_mae: 10.9534\n",
      "Epoch 217/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 111.6831 - mae: 6.9739 - val_loss: 245.7484 - val_mae: 11.2505\n",
      "Epoch 218/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 95.9405 - mae: 6.3575 - val_loss: 231.1709 - val_mae: 11.1629\n",
      "Epoch 219/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 132.0925 - mae: 7.1198 - val_loss: 229.5191 - val_mae: 10.7660\n",
      "Epoch 220/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 118.1479 - mae: 6.8466 - val_loss: 237.6945 - val_mae: 10.9689\n",
      "Epoch 221/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 105.8091 - mae: 6.5593 - val_loss: 227.1914 - val_mae: 10.8900\n",
      "Epoch 222/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 103.8444 - mae: 7.0059 - val_loss: 238.3816 - val_mae: 10.8364\n",
      "Epoch 223/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 131.9572 - mae: 7.2045 - val_loss: 251.1019 - val_mae: 11.4297\n",
      "Epoch 224/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 117.5684 - mae: 7.1162 - val_loss: 237.6285 - val_mae: 11.0715\n",
      "Epoch 225/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 99.5663 - mae: 6.6336 - val_loss: 231.8508 - val_mae: 10.6143\n",
      "Epoch 226/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 121.4434 - mae: 7.1933 - val_loss: 234.2988 - val_mae: 10.9230\n",
      "Epoch 227/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 116.6402 - mae: 7.1149 - val_loss: 221.3226 - val_mae: 10.7082\n",
      "Epoch 228/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 131.7904 - mae: 7.3117 - val_loss: 233.8530 - val_mae: 10.9540\n",
      "Epoch 229/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 100.8408 - mae: 6.4829 - val_loss: 224.4687 - val_mae: 10.4035\n",
      "Epoch 230/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 137.4452 - mae: 6.9885 - val_loss: 217.4592 - val_mae: 10.5559\n",
      "Epoch 231/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 137.0862 - mae: 7.3322 - val_loss: 242.6497 - val_mae: 11.0276\n",
      "Epoch 232/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 104.3837 - mae: 6.5038 - val_loss: 238.7102 - val_mae: 11.0876\n",
      "Epoch 233/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 120.2227 - mae: 7.5833 - val_loss: 226.0277 - val_mae: 10.4875\n",
      "Epoch 234/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 99.9754 - mae: 6.3278 - val_loss: 257.8041 - val_mae: 11.7173\n",
      "Epoch 235/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 131.9259 - mae: 7.6796 - val_loss: 219.6232 - val_mae: 10.6883\n",
      "Epoch 236/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 125.7816 - mae: 7.5635 - val_loss: 226.8254 - val_mae: 10.4891\n",
      "Epoch 237/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 98.1687 - mae: 6.0175 - val_loss: 231.3495 - val_mae: 10.7160\n",
      "Epoch 238/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 97.6547 - mae: 6.2674 - val_loss: 217.6269 - val_mae: 10.5288\n",
      "Epoch 239/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 134.8636 - mae: 7.2296 - val_loss: 224.1001 - val_mae: 10.3142\n",
      "Epoch 240/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 131.2391 - mae: 6.9840 - val_loss: 222.9903 - val_mae: 10.6611\n",
      "Epoch 241/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 113.3696 - mae: 7.0127 - val_loss: 224.8775 - val_mae: 10.5540\n",
      "Epoch 242/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 124.6174 - mae: 6.7958 - val_loss: 238.2006 - val_mae: 10.8974\n",
      "Epoch 243/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 122.3273 - mae: 7.2243 - val_loss: 224.2013 - val_mae: 10.6330\n",
      "Epoch 244/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 116.7137 - mae: 7.2970 - val_loss: 226.3488 - val_mae: 10.8461\n",
      "Epoch 245/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 115.7390 - mae: 7.2603 - val_loss: 225.0753 - val_mae: 11.2608\n",
      "Epoch 246/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 106.7735 - mae: 6.7249 - val_loss: 225.9441 - val_mae: 10.7219\n",
      "Epoch 247/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 97.9166 - mae: 6.4073 - val_loss: 223.4568 - val_mae: 10.3385\n",
      "Epoch 248/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 135.2115 - mae: 7.4176 - val_loss: 226.6242 - val_mae: 10.7374\n",
      "Epoch 249/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 115.6292 - mae: 7.2738 - val_loss: 247.1072 - val_mae: 11.5668\n",
      "Epoch 250/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 116.5003 - mae: 7.5556 - val_loss: 225.2067 - val_mae: 10.8266\n",
      "Epoch 251/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 142.3320 - mae: 7.9990 - val_loss: 233.8132 - val_mae: 10.8073\n",
      "Epoch 252/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 109.3911 - mae: 7.0358 - val_loss: 246.9494 - val_mae: 11.5850\n",
      "Epoch 253/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 125.9346 - mae: 7.6844 - val_loss: 229.1488 - val_mae: 10.6972\n",
      "Epoch 254/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 122.4397 - mae: 6.9852 - val_loss: 226.7044 - val_mae: 10.8343\n",
      "Epoch 255/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 107.5372 - mae: 6.8726 - val_loss: 211.3023 - val_mae: 10.1161\n",
      "Epoch 256/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 127.0492 - mae: 6.8427 - val_loss: 223.0297 - val_mae: 10.5550\n",
      "Epoch 257/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 101.8322 - mae: 6.0784 - val_loss: 226.0404 - val_mae: 10.7354\n",
      "Epoch 258/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 98.5877 - mae: 6.6486 - val_loss: 221.7096 - val_mae: 10.5683\n",
      "Epoch 259/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 86.1761 - mae: 5.9828 - val_loss: 222.7967 - val_mae: 10.4984\n",
      "Epoch 260/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 113.4645 - mae: 6.6529 - val_loss: 221.2711 - val_mae: 10.2175\n",
      "Epoch 261/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 95.3152 - mae: 6.3021 - val_loss: 226.1814 - val_mae: 10.8464\n",
      "Epoch 262/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 103.2395 - mae: 6.4461 - val_loss: 225.6097 - val_mae: 10.3806\n",
      "Epoch 263/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 98.5749 - mae: 6.3091 - val_loss: 211.1709 - val_mae: 10.4251\n",
      "Epoch 264/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 84.3554 - mae: 5.9986 - val_loss: 241.6332 - val_mae: 11.2389\n",
      "Epoch 265/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 95.7833 - mae: 6.3200 - val_loss: 212.8900 - val_mae: 10.3594\n",
      "Epoch 266/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 100.5458 - mae: 6.3862 - val_loss: 230.6483 - val_mae: 10.7022\n",
      "Epoch 267/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 102.7012 - mae: 6.4243 - val_loss: 202.6906 - val_mae: 9.8349\n",
      "Epoch 268/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 118.1942 - mae: 6.8164 - val_loss: 216.2354 - val_mae: 10.0648\n",
      "Epoch 269/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 124.9102 - mae: 6.6445 - val_loss: 216.3691 - val_mae: 10.4649\n",
      "Epoch 270/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 87.8190 - mae: 5.9491 - val_loss: 210.8465 - val_mae: 10.1770\n",
      "Epoch 271/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 120.8973 - mae: 6.9488 - val_loss: 221.7678 - val_mae: 10.4696\n",
      "Epoch 272/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 116.1214 - mae: 6.5468 - val_loss: 208.1430 - val_mae: 10.1059\n",
      "Epoch 273/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 109.7696 - mae: 6.2925 - val_loss: 218.6553 - val_mae: 10.5205\n",
      "Epoch 274/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 103.6973 - mae: 6.2603 - val_loss: 221.5165 - val_mae: 10.5439\n",
      "Epoch 275/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 98.0264 - mae: 6.4766 - val_loss: 218.7545 - val_mae: 10.6351\n",
      "Epoch 276/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 97.6240 - mae: 6.3745 - val_loss: 240.7612 - val_mae: 11.1035\n",
      "Epoch 277/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 108.3278 - mae: 6.8050 - val_loss: 201.9580 - val_mae: 9.8432\n",
      "Epoch 278/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 100.9339 - mae: 6.6860 - val_loss: 237.6375 - val_mae: 10.8592\n",
      "Epoch 279/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 102.5002 - mae: 6.6709 - val_loss: 210.1946 - val_mae: 10.3239\n",
      "Epoch 280/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 108.4631 - mae: 6.3239 - val_loss: 211.7774 - val_mae: 9.9586\n",
      "Epoch 281/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 109.6498 - mae: 6.4218 - val_loss: 223.3106 - val_mae: 10.5921\n",
      "Epoch 282/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 80.8200 - mae: 5.7558 - val_loss: 219.7466 - val_mae: 10.6781\n",
      "Epoch 283/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 120.4065 - mae: 7.2050 - val_loss: 208.6196 - val_mae: 9.8357\n",
      "Epoch 284/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 114.8949 - mae: 6.6956 - val_loss: 227.3567 - val_mae: 10.3490\n",
      "Epoch 285/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 110.8916 - mae: 6.7281 - val_loss: 226.6814 - val_mae: 10.8046\n",
      "Epoch 286/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 95.0232 - mae: 6.5832 - val_loss: 212.1599 - val_mae: 10.1705\n",
      "Epoch 287/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 88.2333 - mae: 5.7170 - val_loss: 212.7957 - val_mae: 9.8013\n",
      "Epoch 288/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 86.3449 - mae: 5.6691 - val_loss: 210.5573 - val_mae: 10.2402\n",
      "Epoch 289/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 99.1785 - mae: 6.0408 - val_loss: 235.4846 - val_mae: 11.3150\n",
      "Epoch 290/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 103.1554 - mae: 6.6589 - val_loss: 218.4962 - val_mae: 9.9462\n",
      "Epoch 291/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 111.6429 - mae: 6.9266 - val_loss: 238.2386 - val_mae: 10.7571\n",
      "Epoch 292/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 147.5787 - mae: 7.8357 - val_loss: 221.2150 - val_mae: 10.4282\n",
      "Epoch 293/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 95.5417 - mae: 5.8157 - val_loss: 237.6824 - val_mae: 11.1442\n",
      "Epoch 294/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 90.8353 - mae: 6.3509 - val_loss: 205.1966 - val_mae: 9.7003\n",
      "Epoch 295/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 105.2881 - mae: 6.4871 - val_loss: 223.4890 - val_mae: 10.5010\n",
      "Epoch 296/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 85.8299 - mae: 5.9230 - val_loss: 220.9653 - val_mae: 10.7577\n",
      "Epoch 297/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 102.1916 - mae: 6.5261 - val_loss: 208.8593 - val_mae: 9.8156\n",
      "Epoch 298/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 75.1634 - mae: 5.5263 - val_loss: 239.9361 - val_mae: 11.4605\n",
      "Epoch 299/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 93.5511 - mae: 6.3735 - val_loss: 207.4621 - val_mae: 10.0814\n",
      "Epoch 300/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 99.6322 - mae: 6.4214 - val_loss: 209.0042 - val_mae: 9.5299\n",
      "Epoch 301/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 99.1821 - mae: 6.3844 - val_loss: 209.7119 - val_mae: 10.4114\n",
      "Epoch 302/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 93.5026 - mae: 5.9462 - val_loss: 238.7518 - val_mae: 11.3041\n",
      "Epoch 303/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 83.3445 - mae: 6.2479 - val_loss: 194.8590 - val_mae: 9.8865\n",
      "Epoch 304/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 109.2314 - mae: 6.6789 - val_loss: 210.0213 - val_mae: 9.7489\n",
      "Epoch 305/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 87.2552 - mae: 5.9762 - val_loss: 250.4649 - val_mae: 11.6320\n",
      "Epoch 306/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 121.7014 - mae: 7.6277 - val_loss: 211.1454 - val_mae: 9.8635\n",
      "Epoch 307/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 116.6345 - mae: 6.4777 - val_loss: 194.6135 - val_mae: 9.7270\n",
      "Epoch 308/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 91.5687 - mae: 6.5451 - val_loss: 255.9636 - val_mae: 11.6116\n",
      "Epoch 309/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 94.8259 - mae: 6.3355 - val_loss: 259.5638 - val_mae: 11.8535\n",
      "Epoch 310/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 104.6829 - mae: 7.0719 - val_loss: 201.2861 - val_mae: 10.0268\n",
      "Epoch 311/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 108.5773 - mae: 7.2012 - val_loss: 201.1944 - val_mae: 9.7835\n",
      "Epoch 312/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 93.6128 - mae: 5.9360 - val_loss: 231.7637 - val_mae: 11.1290\n",
      "Epoch 313/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 96.7560 - mae: 6.4843 - val_loss: 203.6501 - val_mae: 9.8563\n",
      "Epoch 314/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 88.7940 - mae: 5.7335 - val_loss: 212.0356 - val_mae: 9.8351\n",
      "Epoch 315/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 81.5957 - mae: 5.6267 - val_loss: 201.2347 - val_mae: 10.1088\n",
      "Epoch 316/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 102.7625 - mae: 6.5555 - val_loss: 211.3587 - val_mae: 10.4001\n",
      "Epoch 317/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 80.8178 - mae: 5.7630 - val_loss: 210.1621 - val_mae: 10.0116\n",
      "Epoch 318/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 86.7527 - mae: 5.5471 - val_loss: 187.4839 - val_mae: 9.6140\n",
      "Epoch 319/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 96.5313 - mae: 5.9526 - val_loss: 200.1003 - val_mae: 9.8162\n",
      "Epoch 320/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 78.3029 - mae: 5.5841 - val_loss: 202.6662 - val_mae: 9.9519\n",
      "Epoch 321/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 90.5033 - mae: 5.8057 - val_loss: 218.3257 - val_mae: 10.8594\n",
      "Epoch 322/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 81.7920 - mae: 5.7579 - val_loss: 216.5859 - val_mae: 10.2983\n",
      "Epoch 323/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 88.3455 - mae: 5.7440 - val_loss: 191.5868 - val_mae: 9.7024\n",
      "Epoch 324/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 87.7820 - mae: 5.6740 - val_loss: 207.9068 - val_mae: 9.9669\n",
      "Epoch 325/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 75.7150 - mae: 5.1693 - val_loss: 197.2420 - val_mae: 9.7497\n",
      "Epoch 326/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 72.1586 - mae: 5.3089 - val_loss: 230.8943 - val_mae: 11.1451\n",
      "Epoch 327/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 93.9715 - mae: 6.3563 - val_loss: 200.1821 - val_mae: 9.5350\n",
      "Epoch 328/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 86.2443 - mae: 5.9250 - val_loss: 202.1919 - val_mae: 9.9206\n",
      "Epoch 329/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 66.9188 - mae: 5.0511 - val_loss: 190.4057 - val_mae: 9.4550\n",
      "Epoch 330/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 82.9176 - mae: 5.6017 - val_loss: 199.9807 - val_mae: 9.5830\n",
      "Epoch 331/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 88.9032 - mae: 5.6775 - val_loss: 197.1434 - val_mae: 9.6277\n",
      "Epoch 332/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 102.3199 - mae: 6.0548 - val_loss: 209.0078 - val_mae: 10.1423\n",
      "Epoch 333/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 79.9378 - mae: 5.5838 - val_loss: 198.5605 - val_mae: 9.8043\n",
      "Epoch 334/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 81.4188 - mae: 5.4928 - val_loss: 226.5581 - val_mae: 11.0776\n",
      "Epoch 335/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 109.0375 - mae: 6.9876 - val_loss: 198.8128 - val_mae: 9.6973\n",
      "Epoch 336/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 91.3643 - mae: 6.2080 - val_loss: 197.6243 - val_mae: 9.5425\n",
      "Epoch 337/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 91.3779 - mae: 6.0990 - val_loss: 179.8888 - val_mae: 9.4295\n",
      "Epoch 338/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 79.8841 - mae: 5.7756 - val_loss: 211.8819 - val_mae: 10.0453\n",
      "Epoch 339/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 89.4990 - mae: 5.7324 - val_loss: 205.8519 - val_mae: 10.2590\n",
      "Epoch 340/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 90.0173 - mae: 6.0824 - val_loss: 200.8362 - val_mae: 9.7570\n",
      "Epoch 341/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 108.0224 - mae: 6.2789 - val_loss: 204.6897 - val_mae: 9.8623\n",
      "Epoch 342/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 97.4088 - mae: 6.4885 - val_loss: 203.4179 - val_mae: 9.8148\n",
      "Epoch 343/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 84.2128 - mae: 5.7092 - val_loss: 212.5214 - val_mae: 10.3698\n",
      "Epoch 344/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 96.9203 - mae: 6.1913 - val_loss: 205.7569 - val_mae: 10.3385\n",
      "Epoch 345/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 86.8907 - mae: 5.8655 - val_loss: 192.2439 - val_mae: 9.4751\n",
      "Epoch 346/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 80.0288 - mae: 5.2934 - val_loss: 203.0262 - val_mae: 9.7109\n",
      "Epoch 347/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 84.3589 - mae: 5.4892 - val_loss: 184.0750 - val_mae: 9.2686\n",
      "Epoch 348/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 81.5860 - mae: 5.5019 - val_loss: 212.9223 - val_mae: 10.6816\n",
      "Epoch 349/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 87.0425 - mae: 5.8714 - val_loss: 198.8322 - val_mae: 9.7496\n",
      "Epoch 350/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 85.6605 - mae: 5.6788 - val_loss: 200.4999 - val_mae: 9.9061\n",
      "Epoch 351/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 77.2842 - mae: 5.9032 - val_loss: 211.4678 - val_mae: 10.5539\n",
      "Epoch 352/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 88.6096 - mae: 6.2811 - val_loss: 196.7973 - val_mae: 9.8627\n",
      "Epoch 353/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 83.6378 - mae: 5.7493 - val_loss: 195.7122 - val_mae: 9.6727\n",
      "Epoch 354/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 100.6534 - mae: 6.1922 - val_loss: 202.1539 - val_mae: 9.8161\n",
      "Epoch 355/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 81.5936 - mae: 5.6533 - val_loss: 231.0932 - val_mae: 11.2189\n",
      "Epoch 356/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 102.3856 - mae: 7.0614 - val_loss: 204.6234 - val_mae: 9.7649\n",
      "Epoch 357/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 81.8295 - mae: 6.0163 - val_loss: 201.3897 - val_mae: 9.6655\n",
      "Epoch 358/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 105.6432 - mae: 6.8361 - val_loss: 204.4998 - val_mae: 9.7149\n",
      "Epoch 359/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 115.7616 - mae: 6.4092 - val_loss: 194.2207 - val_mae: 9.3441\n",
      "Epoch 360/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 81.2521 - mae: 5.5154 - val_loss: 209.5917 - val_mae: 10.2009\n",
      "Epoch 361/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 89.0954 - mae: 5.8947 - val_loss: 196.1965 - val_mae: 9.7570\n",
      "Epoch 362/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 78.7110 - mae: 5.3625 - val_loss: 204.1073 - val_mae: 9.7936\n",
      "Epoch 363/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 81.2024 - mae: 5.6272 - val_loss: 195.9173 - val_mae: 9.7486\n",
      "Epoch 364/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 69.9283 - mae: 5.0596 - val_loss: 195.8771 - val_mae: 9.6555\n",
      "Epoch 365/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 87.4577 - mae: 5.5731 - val_loss: 194.5937 - val_mae: 9.5350\n",
      "Epoch 366/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 85.8942 - mae: 5.6133 - val_loss: 192.3967 - val_mae: 9.4131\n",
      "Epoch 367/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 75.4943 - mae: 5.2781 - val_loss: 220.1726 - val_mae: 10.7023\n",
      "Epoch 368/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 73.1330 - mae: 5.9065 - val_loss: 190.2354 - val_mae: 9.4835\n",
      "Epoch 369/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 93.8280 - mae: 6.2662 - val_loss: 195.2126 - val_mae: 9.3237\n",
      "Epoch 370/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 75.7390 - mae: 5.0634 - val_loss: 193.5278 - val_mae: 9.5244\n",
      "Epoch 371/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 73.2787 - mae: 5.2729 - val_loss: 202.1910 - val_mae: 10.0489\n",
      "Epoch 372/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 100.4369 - mae: 6.0112 - val_loss: 198.7285 - val_mae: 9.7792\n",
      "Epoch 373/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 77.4335 - mae: 5.2688 - val_loss: 194.7148 - val_mae: 9.5465\n",
      "Epoch 374/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 79.2148 - mae: 5.0454 - val_loss: 197.6415 - val_mae: 9.5685\n",
      "Epoch 375/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 64.7818 - mae: 4.9092 - val_loss: 198.3064 - val_mae: 9.6892\n",
      "Epoch 376/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 80.3761 - mae: 5.3501 - val_loss: 205.1563 - val_mae: 10.0170\n",
      "Epoch 377/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 81.4176 - mae: 5.4080 - val_loss: 206.1349 - val_mae: 9.8373\n",
      "Epoch 378/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 69.2012 - mae: 5.0630 - val_loss: 182.9095 - val_mae: 9.4307\n",
      "Epoch 379/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 58.1867 - mae: 4.5911 - val_loss: 204.3986 - val_mae: 9.8216\n",
      "Epoch 380/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 69.8071 - mae: 5.0561 - val_loss: 189.2727 - val_mae: 9.5544\n",
      "Epoch 381/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 76.3024 - mae: 5.4466 - val_loss: 209.7110 - val_mae: 9.8892\n",
      "Epoch 382/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 81.2714 - mae: 5.2905 - val_loss: 204.5265 - val_mae: 10.2047\n",
      "Epoch 383/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 72.6398 - mae: 5.3968 - val_loss: 213.8840 - val_mae: 10.2724\n",
      "Epoch 384/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 63.4559 - mae: 5.2397 - val_loss: 179.8602 - val_mae: 9.1691\n",
      "Epoch 385/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 85.2288 - mae: 5.9192 - val_loss: 205.2203 - val_mae: 10.0371\n",
      "Epoch 386/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 77.1321 - mae: 5.8599 - val_loss: 192.0815 - val_mae: 9.3089\n",
      "Epoch 387/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 71.1145 - mae: 5.3663 - val_loss: 197.1305 - val_mae: 9.6736\n",
      "Epoch 388/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 93.0916 - mae: 5.6756 - val_loss: 212.8677 - val_mae: 9.9576\n",
      "Epoch 389/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 80.3910 - mae: 5.6228 - val_loss: 192.2050 - val_mae: 9.5838\n",
      "Epoch 390/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 85.1267 - mae: 5.3925 - val_loss: 206.5087 - val_mae: 9.9820\n",
      "Epoch 391/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 73.0978 - mae: 5.0691 - val_loss: 197.8454 - val_mae: 9.8568\n",
      "Epoch 392/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 71.3164 - mae: 5.4652 - val_loss: 206.7525 - val_mae: 9.7213\n",
      "Epoch 393/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 76.0160 - mae: 5.6372 - val_loss: 211.4443 - val_mae: 10.0498\n",
      "Epoch 394/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 83.6265 - mae: 5.8292 - val_loss: 190.3790 - val_mae: 9.4085\n",
      "Epoch 395/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 86.3667 - mae: 5.5822 - val_loss: 215.0769 - val_mae: 10.3215\n",
      "Epoch 396/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 72.7970 - mae: 5.4555 - val_loss: 211.1252 - val_mae: 10.2964\n",
      "Epoch 397/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 102.4124 - mae: 6.4849 - val_loss: 194.7641 - val_mae: 9.6504\n",
      "Epoch 398/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 89.0817 - mae: 6.1007 - val_loss: 195.5992 - val_mae: 9.5487\n",
      "Epoch 399/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 88.5061 - mae: 6.2386 - val_loss: 203.0215 - val_mae: 9.5307\n",
      "Epoch 400/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 80.6216 - mae: 5.8359 - val_loss: 191.5906 - val_mae: 9.6916\n",
      "Epoch 401/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 79.9545 - mae: 5.7572 - val_loss: 194.6086 - val_mae: 9.7208\n",
      "Epoch 402/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 57.8497 - mae: 4.6697 - val_loss: 213.7288 - val_mae: 10.3380\n",
      "Epoch 403/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 93.5940 - mae: 6.0176 - val_loss: 214.1327 - val_mae: 10.6017\n",
      "Epoch 404/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 86.9533 - mae: 6.4295 - val_loss: 210.7030 - val_mae: 10.2009\n",
      "Epoch 405/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 74.7511 - mae: 5.4338 - val_loss: 182.8512 - val_mae: 9.3173\n",
      "Epoch 406/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 88.3034 - mae: 5.8662 - val_loss: 215.8459 - val_mae: 10.2222\n",
      "Epoch 407/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 79.9094 - mae: 5.3548 - val_loss: 185.9200 - val_mae: 9.3641\n",
      "Epoch 408/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 105.2147 - mae: 5.9720 - val_loss: 197.4295 - val_mae: 9.3947\n",
      "Epoch 409/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 102.0705 - mae: 5.9536 - val_loss: 195.1569 - val_mae: 9.5240\n",
      "Epoch 410/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 81.6401 - mae: 5.5287 - val_loss: 192.3429 - val_mae: 9.6366\n",
      "Epoch 411/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 64.9316 - mae: 4.8092 - val_loss: 198.3109 - val_mae: 9.6252\n",
      "Epoch 412/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 68.3665 - mae: 4.9691 - val_loss: 189.7990 - val_mae: 9.4195\n",
      "Epoch 413/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 84.7248 - mae: 5.3451 - val_loss: 197.3037 - val_mae: 9.4093\n",
      "Epoch 414/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 62.7571 - mae: 4.6942 - val_loss: 200.8403 - val_mae: 9.9806\n",
      "Epoch 415/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 72.0808 - mae: 5.3453 - val_loss: 200.7487 - val_mae: 9.9071\n",
      "Epoch 416/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 69.3677 - mae: 5.2417 - val_loss: 198.8003 - val_mae: 9.6403\n",
      "Epoch 417/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 72.0766 - mae: 5.1067 - val_loss: 199.1872 - val_mae: 9.5572\n",
      "Epoch 418/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 85.2895 - mae: 5.4625 - val_loss: 202.2507 - val_mae: 9.8925\n",
      "Epoch 419/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 67.5054 - mae: 4.9461 - val_loss: 191.0954 - val_mae: 9.5290\n",
      "Epoch 420/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 75.5162 - mae: 5.2299 - val_loss: 195.9310 - val_mae: 9.6019\n",
      "Epoch 421/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 79.5803 - mae: 5.4743 - val_loss: 232.9756 - val_mae: 10.8588\n",
      "Epoch 422/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 88.8963 - mae: 6.2846 - val_loss: 195.2428 - val_mae: 9.4227\n",
      "Epoch 423/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 84.0418 - mae: 5.4338 - val_loss: 205.4710 - val_mae: 9.4919\n",
      "Epoch 424/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 76.0892 - mae: 5.1859 - val_loss: 202.2787 - val_mae: 9.6737\n",
      "Epoch 425/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 77.0551 - mae: 5.0345 - val_loss: 190.5659 - val_mae: 9.5601\n",
      "Epoch 426/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 70.1507 - mae: 4.8855 - val_loss: 234.3800 - val_mae: 10.8601\n",
      "Epoch 427/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 75.5563 - mae: 5.5019 - val_loss: 193.2896 - val_mae: 9.7688\n",
      "Epoch 428/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 82.0456 - mae: 5.8219 - val_loss: 198.7107 - val_mae: 9.7574\n",
      "Epoch 429/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 89.8737 - mae: 5.6187 - val_loss: 191.7444 - val_mae: 9.3162\n",
      "Epoch 430/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 70.6781 - mae: 4.9830 - val_loss: 187.6083 - val_mae: 9.1922\n",
      "Epoch 431/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 78.5140 - mae: 5.4935 - val_loss: 189.3918 - val_mae: 9.2611\n",
      "Epoch 432/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 69.6847 - mae: 5.3993 - val_loss: 247.9195 - val_mae: 11.5104\n",
      "Epoch 433/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 83.6198 - mae: 6.4352 - val_loss: 192.8196 - val_mae: 9.6064\n",
      "Epoch 434/500\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 68.0416 - mae: 5.2512 - val_loss: 205.6998 - val_mae: 9.6250\n",
      "Epoch 434: early stopping\n",
      "Restoring model weights from the end of the best epoch: 384.\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 997us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  model  R2_train  MAE_train  MAPE_train  RMSE_train   R2_test   MAE_test  \\\n",
       "0   ANN  0.935074    6.38837    6.729555   10.309365  0.834066  11.085776   \n",
       "\n",
       "   MAPE_test  RMSE_test  \n",
       "0  12.279551   16.86994  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>R2_train</th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>MAPE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>R2_test</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>MAPE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>0.935074</td>\n",
       "      <td>6.38837</td>\n",
       "      <td>6.729555</td>\n",
       "      <td>10.309365</td>\n",
       "      <td>0.834066</td>\n",
       "      <td>11.085776</td>\n",
       "      <td>12.279551</td>\n",
       "      <td>16.86994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. 模型性能汇总",
   "id": "24c96767df32d41e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T05:22:17.734127Z",
     "start_time": "2024-04-19T05:22:17.721857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 模型评估\n",
    "models_df = pd.concat([krr_df, svr_df, rfr_df, gbr_df, xgb_df, ann_df], axis=0)\n",
    "models_df"
   ],
   "id": "b9f9b5a8e63555f0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  model  R2_train  MAE_train  MAPE_train  RMSE_train   R2_test   MAE_test  \\\n",
       "0   KRR  0.435135  22.894784   31.818375   30.408537  0.446760  23.182953   \n",
       "0   SVR  0.711955  14.185514   16.157653   21.714667  0.673651  17.315961   \n",
       "0    RF  0.979680   3.836267    4.787475    5.767510  0.844773  10.142849   \n",
       "0   GBR  0.998413   1.072222    1.302167    1.611991  0.918238   6.552700   \n",
       "0   XGB  0.995994   1.843803    2.196843    2.560729  0.928432   6.589210   \n",
       "0   ANN  0.935074   6.388370    6.729555   10.309365  0.834066  11.085776   \n",
       "\n",
       "   MAPE_test  RMSE_test  \n",
       "0  31.754049  30.803639  \n",
       "0  21.287540  23.658464  \n",
       "0  13.554456  16.316589  \n",
       "0   8.510915  11.841927  \n",
       "0   8.734536  11.079110  \n",
       "0  12.279551  16.869940  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>R2_train</th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>MAPE_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>R2_test</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>MAPE_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KRR</td>\n",
       "      <td>0.435135</td>\n",
       "      <td>22.894784</td>\n",
       "      <td>31.818375</td>\n",
       "      <td>30.408537</td>\n",
       "      <td>0.446760</td>\n",
       "      <td>23.182953</td>\n",
       "      <td>31.754049</td>\n",
       "      <td>30.803639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.711955</td>\n",
       "      <td>14.185514</td>\n",
       "      <td>16.157653</td>\n",
       "      <td>21.714667</td>\n",
       "      <td>0.673651</td>\n",
       "      <td>17.315961</td>\n",
       "      <td>21.287540</td>\n",
       "      <td>23.658464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.979680</td>\n",
       "      <td>3.836267</td>\n",
       "      <td>4.787475</td>\n",
       "      <td>5.767510</td>\n",
       "      <td>0.844773</td>\n",
       "      <td>10.142849</td>\n",
       "      <td>13.554456</td>\n",
       "      <td>16.316589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GBR</td>\n",
       "      <td>0.998413</td>\n",
       "      <td>1.072222</td>\n",
       "      <td>1.302167</td>\n",
       "      <td>1.611991</td>\n",
       "      <td>0.918238</td>\n",
       "      <td>6.552700</td>\n",
       "      <td>8.510915</td>\n",
       "      <td>11.841927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.995994</td>\n",
       "      <td>1.843803</td>\n",
       "      <td>2.196843</td>\n",
       "      <td>2.560729</td>\n",
       "      <td>0.928432</td>\n",
       "      <td>6.589210</td>\n",
       "      <td>8.734536</td>\n",
       "      <td>11.079110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>0.935074</td>\n",
       "      <td>6.388370</td>\n",
       "      <td>6.729555</td>\n",
       "      <td>10.309365</td>\n",
       "      <td>0.834066</td>\n",
       "      <td>11.085776</td>\n",
       "      <td>12.279551</td>\n",
       "      <td>16.869940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "sklearn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
